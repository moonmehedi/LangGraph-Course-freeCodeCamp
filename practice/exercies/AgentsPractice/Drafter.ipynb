{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba91ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function dotenv.main.load_dotenv(dotenv_path: Union[str, ForwardRef('os.PathLike[str]'), NoneType] = None, stream: Optional[IO[str]] = None, verbose: bool = False, override: bool = False, interpolate: bool = True, encoding: Optional[str] = 'utf-8') -> bool>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated, Sequence, TypedDict\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.messages import ToolMessage,HumanMessage,AIMessage\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f8768ff",
   "metadata": {},
   "outputs": [],
   "source": [
    " #this is the global variable to store document content\n",
    "\n",
    "document_content = ''\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage],add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540b9d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def update(content:str)->str:\n",
    "    \"\"\" Update the document with the provided content.\"\"\"\n",
    "    global document_content\n",
    "    document_content = content\n",
    "    return f\"Document has been updated successfully! The current content is :\\n{document_content}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def save(filename:str)->str:\n",
    "    \"\"\" \n",
    "    Save the current document to a text file and finish the process.\n",
    "\n",
    "    Args:\n",
    "    filename: Name for the text file  \n",
    "    \"\"\"\n",
    "\n",
    "    global document_content\n",
    "\n",
    "    if not filename.endswith('.txt'):\n",
    "        filename = f\"{filename}.txt\"\n",
    "\n",
    "    try:\n",
    "        with open(filename,'w') as file:\n",
    "            file.write(document_content)\n",
    "        print(f'\\n Document has been saved to :',{filename})\n",
    "        return f'Document has been saved successfully to {filename}.'\n",
    "    except Exception as e:\n",
    "        return f\"Error saving document :{str(e)}\"\n",
    "    \n",
    "\n",
    "tools = [update,save]\n",
    "\n",
    "model = ChatOpenAI(model = 'gpt-4o-mini').bind_tools(tools)\n",
    "\n",
    "\n",
    "def our_agent(state:AgentState)->AgentState:\n",
    "    system_prompt = SystemMessage(content=f\"\"\"\n",
    "    You are Drafter, a helpful writing assistant. You are going to help the user update and modify documents.\n",
    "    \n",
    "    - If the user wants to update or modify content, use the 'update' tool with the complete updated content.\n",
    "    - If the user wants to save and finish, you need to use the 'save' tool.\n",
    "    - Make sure to always show the current document state after modifications.\n",
    "    \n",
    "    The current document content is:{document_content}\n",
    "    \"\"\")\n",
    "    if not state['messages']:\n",
    "        user_input = input(\"I'm ready to help you update a document. What would you like to create ?\\n\")\n",
    "        user_message = HumanMessage(content=user_input)\n",
    "    else:\n",
    "        user_input = input('\\n what would y like to do with the document ? ')\n",
    "        print(\"\\n USER:{user_input}\")\n",
    "        user_message = HumanMessage(content=user_input)\n",
    "\n",
    "    all_messages = [system_prompt] + list(state['messages'])+user_message\n",
    "\n",
    "    response = model.invoke(all_messages)\n",
    "\n",
    "    print(f'\\n AI: {response.content}')\n",
    "\n",
    "    #if tool call happen print it\n",
    "\n",
    "    if hasattr(response,'tool_calls') and response.tool_calls:\n",
    "        print(f'Using Tools:{[tc.name for tc in response.tool_calls]}')\n",
    "\n",
    "    return {'messages':list(state['message']) + [user_message,response]}\n",
    "\n",
    "\n",
    "def should_continue(state:AgentState) -> str:\n",
    "    \"\"\" Determine if we should continue or end the conversationf\"\"\"\n",
    "\n",
    "    messages  = state['messages']\n",
    "\n",
    "    if not messages:\n",
    "        return 'continue'\n",
    "    \n",
    "    for message in reversed(messages):\n",
    "        if(isinstance(message, ToolMessage)) and 'saved' in message.content.lower() and 'document' in message.content.lower():\n",
    "            return 'end_node'\n",
    "    return 'continue'\n",
    "\n",
    "# print it nicely\n",
    "\n",
    "def print_message(messages):\n",
    "    \"\"\"Function I made to print the messages in a more reliable formate \"\"\"\n",
    "    if not messages:\n",
    "        return \n",
    "    \n",
    "    for message in messages[-3:]:\n",
    "        if isinstance(message,ToolMessage):\n",
    "            print(f'\\n Tool Result :{message.content}')\n",
    "\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node('agent',our_agent)\n",
    "graph.add_node('tools',ToolNode(tools))\n",
    "\n",
    "graph.set_entry_point('agent')\n",
    "graph.add_edge('agent','tools')\n",
    "graph.add_conditional_edges(\n",
    "    'tools',\n",
    "    should_continue,\n",
    "    {\n",
    "        'end_node':END\n",
    "        'continue':'agent'\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "def run_document_agent():\n",
    "    print('\\n ======= DRAFTER ========')\n",
    "\n",
    "    state = {'messages':[]}\n",
    "\n",
    "    for step in app.stream(state, stream_mode='values'):\n",
    "        if 'messages' in step:\n",
    "            print_message(step['messages'])\n",
    "\n",
    "    print(\"\\n ======= Drafter FINISHED =======\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_document_agent()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
